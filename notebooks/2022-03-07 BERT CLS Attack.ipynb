{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b61845-de90-446e-90bb-e3761a3ec2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "098863ba-4cf7-48d2-8527-667e56a7da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from textattack.goal_function_results import ClassificationGoalFunctionResult\n",
    "from textattack.goal_functions import GoalFunction\n",
    "\n",
    "class ReduceSimilarity(GoalFunction):\n",
    "    \"\"\"A goal function for reducing similarity between input and perturbed text.\"\"\"\n",
    "    \n",
    "    def init_attack_example(self, attacked_text, ground_truth_output):\n",
    "        # print('init_attack_example:', attacked_text)\n",
    "        # Store original vector\n",
    "        with torch.no_grad():\n",
    "            self.ground_truth_representation = self.model(ground_truth_output).cpu().squeeze() # [1,emb_dim] -> [emb_dim,]\n",
    "        return super().init_attack_example(attacked_text, ground_truth_output)\n",
    "\n",
    "    def _process_model_outputs(self, inputs, scores):\n",
    "        # Automatically cast a list or ndarray of predictions to a tensor.\n",
    "        if isinstance(scores, list) or isinstance(scores, np.ndarray):\n",
    "            scores = torch.tensor(scores)\n",
    "\n",
    "        # Ensure the returned value is now a tensor.\n",
    "        if not isinstance(scores, torch.Tensor):\n",
    "            raise TypeError(\n",
    "                \"Must have list, np.ndarray, or torch.Tensor of \"\n",
    "                f\"scores. Got type {type(scores)}\"\n",
    "            )\n",
    "\n",
    "        # Validation check on model score dimensions\n",
    "        if scores.ndim == 1:\n",
    "            # Unsqueeze prediction, if it's been squeezed by the model.\n",
    "            if len(inputs) == 1:\n",
    "                scores = scores.unsqueeze(dim=0)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "                )\n",
    "        elif scores.ndim != 2:\n",
    "            # If model somehow returns too may dimensions, throw an error.\n",
    "            raise ValueError(\n",
    "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "            )\n",
    "        elif scores.shape[0] != len(inputs):\n",
    "            # If model returns an incorrect number of scores, throw an error.\n",
    "            raise ValueError(\n",
    "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "            )\n",
    "        return scores.cpu()\n",
    "    \n",
    "    def _is_goal_complete(self, model_output, _):\n",
    "        return False # TODO(jxm): implement?\n",
    "\n",
    "    def _get_score(self, model_output, _):\n",
    "        sim = (\n",
    "            torch.nn.CosineSimilarity(dim=0)(self.ground_truth_representation, model_output)\n",
    "            .item()\n",
    "        )\n",
    "        return 1-sim\n",
    "\n",
    "    def _goal_function_result_type(self):\n",
    "        \"\"\"Returns the class of this goal function's results.\"\"\"\n",
    "        return ClassificationGoalFunctionResult\n",
    "\n",
    "    def extra_repr_keys(self):\n",
    "        return []\n",
    "\n",
    "    def _get_displayed_output(self, raw_output):\n",
    "        sim = (\n",
    "            torch.nn.CosineSimilarity(dim=0)(self.ground_truth_representation, raw_output)\n",
    "        ).item()\n",
    "        return f'{sim:.4f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "190ac8a4-395f-4faa-8f9f-8878ce6db5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack import Attack\n",
    "from textattack.constraints.pre_transformation import (\n",
    "    RepeatModification,\n",
    "    StopwordModification,\n",
    ")\n",
    "\n",
    "from textattack.constraints.grammaticality import PartOfSpeech\n",
    "from textattack.constraints.semantics import WordEmbeddingDistance\n",
    "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
    "\n",
    "from textattack.goal_functions import InputReduction\n",
    "from textattack.search_methods import GreedyWordSwapWIR\n",
    "from textattack.transformations import WordSwapEmbedding\n",
    "\n",
    "from textattack.attack_recipes import AttackRecipe\n",
    "\n",
    "\n",
    "class SimilarityReduction(AttackRecipe):\n",
    "    @staticmethod\n",
    "    def build(model_wrapper):\n",
    "        # At each step, we remove the word with the lowest importance value until\n",
    "        # the model changes its prediction.\n",
    "        transformation = WordSwapEmbedding(max_candidates=50)\n",
    "        constraints = [RepeatModification()]\n",
    "        constraints.append(StopwordModification())\n",
    "        constraints.append(WordEmbeddingDistance(min_cos_sim=0.5))\n",
    "        constraints.append(PartOfSpeech(allow_verb_noun_swap=True))\n",
    "        use_constraint = UniversalSentenceEncoder(\n",
    "            threshold=0.840845057,\n",
    "            metric=\"angular\",\n",
    "            compare_against_original=False,\n",
    "            window_size=15,\n",
    "            skip_text_shorter_than_window=True,\n",
    "        )\n",
    "        constraints.append(use_constraint)\n",
    "        # TODO: Add constraints\n",
    "        goal_function = ReduceSimilarity(model_wrapper, maximizable=True)\n",
    "        \n",
    "        search_method = GreedyWordSwapWIR()\n",
    "\n",
    "        return Attack(goal_function, constraints, transformation, search_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "152cb660-f716-426b-8ac6-68279a6f1d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "textattack: No entry found for goal function <class '__main__.ReduceSimilarity'>.\n",
      "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertModel'> compatible with goal function <class '__main__.ReduceSimilarity'>.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from textattack.models.wrappers import PyTorchModelWrapper\n",
    "\n",
    "model = transformers.AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class HuggingFaceModelWrapper(PyTorchModelWrapper):\n",
    "    \"\"\"Loads a HuggingFace ``transformers`` model and tokenizer.\"\"\"\n",
    "    model: transformers.PreTrainedModel\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "    max_length: int\n",
    "\n",
    "    def __init__(self, model, tokenizer, max_length=128):\n",
    "        assert isinstance(\n",
    "            model, transformers.PreTrainedModel\n",
    "        ), f\"`model` must be of type `transformers.PreTrainedModel`, but got type {type(model)}.\"\n",
    "        assert isinstance(\n",
    "            tokenizer,\n",
    "            (transformers.PreTrainedTokenizer, transformers.PreTrainedTokenizerFast),\n",
    "        ), f\"`tokenizer` must of type `transformers.PreTrainedTokenizer` or `transformers.PreTrainedTokenizerFast`, but got type {type(tokenizer)}.\"\n",
    "\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, text_input_list):\n",
    "        \"\"\"Passes inputs to HuggingFace models as keyword arguments.\n",
    "        (Regular PyTorch ``nn.Module`` models typically take inputs as\n",
    "        positional arguments.)\n",
    "        \"\"\"\n",
    "        # Default max length is set to be int(1e30), so we force 512 to enable batching.\n",
    "        inputs_dict = self.tokenizer(\n",
    "            text_input_list,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        model_device = next(self.model.parameters()).device\n",
    "        inputs_dict.to(model_device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs_dict)\n",
    "        # Outputs will be of shape [batch_size, self.max_length, 768]\n",
    "        outputs = outputs.last_hidden_state[:, 0, :] # get CLS representation\n",
    "        return outputs\n",
    "\n",
    "    \n",
    "    def _tokenize(self, inputs):\n",
    "        \"\"\"Helper method that for `tokenize`\n",
    "        Args:\n",
    "            inputs (list[str]): list of input strings\n",
    "        Returns:\n",
    "            tokens (list[list[str]]): List of list of tokens as strings\n",
    "        \"\"\"\n",
    "        return [\n",
    "            self.tokenizer.convert_ids_to_tokens(\n",
    "                self.tokenizer([x], truncation=True)[\"input_ids\"][0]\n",
    "            )\n",
    "            for x in inputs\n",
    "        ]\n",
    "\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
    "attack = SimilarityReduction.build(model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8580f97-8815-41e3-b3f4-6b74e52d3e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  ReduceSimilarity\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:05<00:15,  5.23s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  25%|██▌       | 1/4 [00:05<00:15,  5.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[205 (327%)]] --> [[205 (222%)]]\n",
      "\n",
      "[[Malaria]] [[deaths]] in [[Africa]] [[fall]] by 5% from [[last]] [[year]]\n",
      "\n",
      "[[Mosquitos]] [[assassinate]] in [[Chau]] [[downturn]] by 5% from [[latter]] [[yr]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  50%|█████     | 2/4 [00:06<00:06,  3.01s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  50%|█████     | 2/4 [00:06<00:06,  3.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[205 (222%)]] --> [[205 (359%)]]\n",
      "\n",
      "[[Washington]] [[Nationals]] [[defeat]] the [[Houston]] [[Astros]] to [[win]] the [[World]] [[Series]]\n",
      "\n",
      "[[Tacoma]] [[Citizenship]] [[bt]] the [[Tulsa]] [[Celtics]] to [[finalist]] the [[Universally]] [[Instalments]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  75%|███████▌  | 3/4 [00:06<00:02,  2.11s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  75%|███████▌  | 3/4 [00:06<00:02,  2.11s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3: 100%|██████████| 4/4 [00:06<00:00,  1.63s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4: 100%|██████████| 4/4 [00:06<00:00,  1.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[205 (366%)]] --> [[205 (369%)]]\n",
      "\n",
      "Exxon Mobil [[hires]] a [[new]] [[CEO]]\n",
      "\n",
      "Exxon Mobil [[renting]] a [[recent]] [[IB]]\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[205 (378%)]] --> [[205 (313%)]]\n",
      "\n",
      "Microsoft [[invests]] $1 [[billion]] in OpenAI\n",
      "\n",
      "Microsoft [[returning]] $1 [[million]] in OpenAI\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 4      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 54.02% |\n",
      "| Average num. words per input: | 8.25   |\n",
      "| Avg num queries:              | 128.0  |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: Logging to CSV at path results.csv\n",
      "textattack: CSVLogger exiting without calling flush().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "result: 205 (327%) --> 205 (222%)\n",
      "\n",
      "Malaria deaths in Africa fall by 5% from last year\n",
      "\n",
      "Mosquitos assassinate in Chau downturn by 5% from latter yr\n",
      "result: 205 (222%) --> 205 (359%)\n",
      "\n",
      "Washington Nationals defeat the Houston Astros to win the World Series\n",
      "\n",
      "Tacoma Citizenship bt the Tulsa Celtics to finalist the Universally Instalments\n",
      "result: 205 (366%) --> 205 (369%)\n",
      "\n",
      "Exxon Mobil hires a new CEO\n",
      "\n",
      "Exxon Mobil renting a recent IB\n",
      "result: 205 (378%) --> 205 (313%)\n",
      "\n",
      "Microsoft invests $1 billion in OpenAI\n",
      "\n",
      "Microsoft returning $1 million in OpenAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/textattack/loggers/csv_logger.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df = self.df.append(row, ignore_index=True)\n",
      "/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/textattack/loggers/csv_logger.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df = self.df.append(row, ignore_index=True)\n",
      "/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/textattack/loggers/csv_logger.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df = self.df.append(row, ignore_index=True)\n",
      "/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/textattack/loggers/csv_logger.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.df = self.df.append(row, ignore_index=True)\n",
      "<ipython-input-57-c25d24cb7b74>:31: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td><font color = orange>Malaria</font> <font color = orange>deaths</font> in <font color = orange>Africa</font> <font color = orange>fall</font> by 5% from <font color = orange>last</font> <font color = orange>year</font></td>\n",
       "      <td><font color = orange>Mosquitos</font> <font color = orange>assassinate</font> in <font color = orange>Chau</font> <font color = orange>downturn</font> by 5% from <font color = orange>latter</font> <font color = orange>yr</font></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483783</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>Malaria deaths in Africa fall by 5% from last year</td>\n",
       "      <td>150</td>\n",
       "      <td>Maximized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td><font color = orange>Washington</font> <font color = orange>Nationals</font> <font color = orange>defeat</font> the <font color = orange>Houston</font> <font color = orange>Astros</font> to <font color = orange>win</font> the <font color = orange>World</font> <font color = orange>Series</font></td>\n",
       "      <td><font color = orange>Tacoma</font> <font color = orange>Citizenship</font> <font color = orange>bt</font> the <font color = orange>Tulsa</font> <font color = orange>Celtics</font> to <font color = orange>finalist</font> the <font color = orange>Universally</font> <font color = orange>Instalments</font></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430628</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5694</td>\n",
       "      <td>Washington Nationals defeat the Houston Astros to win the World Series</td>\n",
       "      <td>236</td>\n",
       "      <td>Maximized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exxon Mobil <font color = orange>hires</font> a <font color = orange>new</font> <font color = orange>CEO</font></td>\n",
       "      <td>Exxon Mobil <font color = orange>renting</font> a <font color = orange>recent</font> <font color = orange>IB</font></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197282</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>Exxon Mobil hires a new CEO</td>\n",
       "      <td>88</td>\n",
       "      <td>Maximized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft <font color = orange>invests</font> $1 <font color = orange>billion</font> in OpenAI</td>\n",
       "      <td>Microsoft <font color = orange>returning</font> $1 <font color = orange>million</font> in OpenAI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132748</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>Microsoft invests $1 billion in OpenAI</td>\n",
       "      <td>38</td>\n",
       "      <td>Maximized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm # tqdm provides us a nice progress bar.\n",
    "from textattack.loggers import CSVLogger # tracks a dataframe for us.\n",
    "from textattack.attack_results import SuccessfulAttackResult\n",
    "from textattack import Attacker\n",
    "from textattack import AttackArgs\n",
    "from textattack.datasets import Dataset\n",
    "\n",
    "custom_dataset = [\n",
    "    'Malaria deaths in Africa fall by 5% from last year',\n",
    "    'Washington Nationals defeat the Houston Astros to win the World Series',\n",
    "    'Exxon Mobil hires a new CEO',\n",
    "    'Microsoft invests $1 billion in OpenAI',\n",
    "]\n",
    "\n",
    "custom_dataset = [(t, t) for t in custom_dataset]\n",
    "\n",
    "attack_args = AttackArgs(num_examples=4)\n",
    "\n",
    "dataset = Dataset(custom_dataset)\n",
    "\n",
    "attacker = Attacker(attack, dataset, attack_args)\n",
    "\n",
    "results_iterable = attacker.attack_dataset()\n",
    "\n",
    "logger = CSVLogger(color_method='html')\n",
    "\n",
    "for result in results_iterable:\n",
    "    print('result:', result)\n",
    "    logger.log_attack_result(result)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(logger.df.to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e266f77-8aa6-43c2-aea1-c2b658446a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
